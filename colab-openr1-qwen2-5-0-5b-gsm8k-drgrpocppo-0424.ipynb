{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# OpenR1 Qwen2.5-0.5B-gsm8k-drgrpocppo 0424 0507\n* num_generations: 8\n* num_train_epochs: 1\n","metadata":{"id":"8ALE-8C-Kv8M"}},{"cell_type":"markdown","source":"https://github.com/lzhxmu/CPPO.git\n","metadata":{"id":"5fQ0dihvKv8O"}},{"cell_type":"markdown","source":"- gpu: L4*1\n- model: Qwen/Qwen2.5-0.5B\n- data: stpete2/openai-gsm8k-part\n- method: drgrpocppo\n- output: Qwen2.5-0.5B-gsm8k-drgrpocppo","metadata":{"id":"-wwJzuRjKv8P"}},{"cell_type":"markdown","source":"###### unique setting for cppo in custom_config2.yaml\n- metric: smallest\n- pruning: 0.5\n- allocation: true\n###### unique setting for drgrpo in custom_config2.yaml\n- scale_rewards: false","metadata":{"id":"jUnbSt6UKv8P"}},{"cell_type":"markdown","source":"## Open-R1\nis an open initiative to replicate and extend the techniques behind DeepSeek-R1, a state-of-the-art reasoning model, in a fully transparent and collaborative way:\n\nhttps://github.com/huggingface/open-r1\n\n","metadata":{"id":"kSZuMdEbKv8Q"}},{"cell_type":"code","source":"import wandb\nsecret_value = \"xxxxx\"\nwandb.login(key=secret_value)\n\n# save metrics into wandb folder\nimport os\nos.environ[\"WANDB_DIR\"] = \"./wandb\"\nwandb.init(project=\"250424drgrpo\", mode=\"online\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:37:51.031315Z","iopub.execute_input":"2025-04-13T16:37:51.031506Z","iopub.status.idle":"2025-04-13T16:37:51.335575Z","shell.execute_reply.started":"2025-04-13T16:37:51.031486Z","shell.execute_reply":"2025-04-13T16:37:51.334959Z"},"colab":{"base_uri":"https://localhost:8080/","height":284},"id":"kFjozsh-Kv8R","outputId":"319cd609-c3d3-4d13-8ec3-49bc81f82996"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstpeteishii\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.10"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250507_134259-6ymroljn</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/stpeteishii/250424drgrpo/runs/6ymroljn' target=\"_blank\">giddy-dream-11</a></strong> to <a href='https://wandb.ai/stpeteishii/250424drgrpo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/stpeteishii/250424drgrpo' target=\"_blank\">https://wandb.ai/stpeteishii/250424drgrpo</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/stpeteishii/250424drgrpo/runs/6ymroljn' target=\"_blank\">https://wandb.ai/stpeteishii/250424drgrpo/runs/6ymroljn</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/stpeteishii/250424drgrpo/runs/6ymroljn?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7b8cd5e07890>"]},"metadata":{},"execution_count":1}],"execution_count":1},{"cell_type":"code","source":"!git clone https://github.com/tztechno/forked_CPPO.git\n!pip install -e ./forked_CPPO\n!pip show forked_CPPO","metadata":{"_uuid":"56441817-9a26-48a8-9e2a-20d0519b1368","_cell_guid":"c938dd8b-8728-417e-b2b8-e5ea9a6531cb","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:37:51.336307Z","iopub.execute_input":"2025-04-13T16:37:51.336538Z","iopub.status.idle":"2025-04-13T16:38:11.319488Z","shell.execute_reply.started":"2025-04-13T16:37:51.336518Z","shell.execute_reply":"2025-04-13T16:38:11.31866Z"},"_kg_hide-output":true,"jupyter":{"outputs_hidden":false},"colab":{"base_uri":"https://localhost:8080/"},"id":"WS2AJkF2Kv8S","outputId":"a4875459-f564-46e8-a7ac-3008f0a66721","collapsed":false},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'forked_CPPO'...\n","remote: Enumerating objects: 746, done.\u001b[K\n","remote: Counting objects: 100% (79/79), done.\u001b[K\n","remote: Compressing objects: 100% (60/60), done.\u001b[K\n","remote: Total 746 (delta 40), reused 3 (delta 3), pack-reused 667 (from 1)\u001b[K\n","Receiving objects: 100% (746/746), 3.76 MiB | 15.42 MiB/s, done.\n","Resolving deltas: 100% (395/395), done.\n","Obtaining file:///content/forked_CPPO\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting trl@ git+https://github.com/huggingface/trl.git@69ad852e5654a77f1695eb4c608906fe0c7e8624 (from open-r1==0.1.0.dev0)\n","  Cloning https://github.com/huggingface/trl.git (to revision 69ad852e5654a77f1695eb4c608906fe0c7e8624) to /tmp/pip-install-6k7x9zfv/trl_523b4f81938640b4ab3907cf7f969df1\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-install-6k7x9zfv/trl_523b4f81938640b4ab3907cf7f969df1\n","  Running command git rev-parse -q --verify 'sha^69ad852e5654a77f1695eb4c608906fe0c7e8624'\n","  Running command git fetch -q https://github.com/huggingface/trl.git 69ad852e5654a77f1695eb4c608906fe0c7e8624\n","  Running command git checkout -q 69ad852e5654a77f1695eb4c608906fe0c7e8624\n","  Resolved https://github.com/huggingface/trl.git to commit 69ad852e5654a77f1695eb4c608906fe0c7e8624\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting accelerate==1.4.0 (from open-r1==0.1.0.dev0)\n","  Downloading accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n","Collecting bitsandbytes>=0.43.0 (from open-r1==0.1.0.dev0)\n","  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: einops>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from open-r1==0.1.0.dev0) (0.8.1)\n","Collecting datasets>=3.2.0 (from open-r1==0.1.0.dev0)\n","  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n","Collecting deepspeed==0.15.4 (from open-r1==0.1.0.dev0)\n","  Downloading deepspeed-0.15.4.tar.gz (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting hf_transfer>=0.1.4 (from open-r1==0.1.0.dev0)\n","  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[cli]<1.0,>=0.19.2->open-r1==0.1.0.dev0) (0.30.2)\n","Collecting langdetect (from open-r1==0.1.0.dev0)\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting latex2sympy2_extended>=1.0.6 (from open-r1==0.1.0.dev0)\n","  Downloading latex2sympy2_extended-1.10.1-py3-none-any.whl.metadata (5.3 kB)\n","Collecting math-verify==0.5.2 (from open-r1==0.1.0.dev0)\n","  Downloading math_verify-0.5.2-py3-none-any.whl.metadata (347 bytes)\n","Collecting liger_kernel==0.5.3 (from open-r1==0.1.0.dev0)\n","  Downloading liger_kernel-0.5.3-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.11/dist-packages (from open-r1==0.1.0.dev0) (24.2)\n","Requirement already satisfied: safetensors>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from open-r1==0.1.0.dev0) (0.5.3)\n","Requirement already satisfied: sentencepiece>=0.1.99 in /usr/local/lib/python3.11/dist-packages (from open-r1==0.1.0.dev0) (0.2.0)\n","Collecting transformers==4.49.0 (from open-r1==0.1.0.dev0)\n","  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wandb>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from open-r1==0.1.0.dev0) (0.19.10)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.4.0->open-r1==0.1.0.dev0) (2.0.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.4.0->open-r1==0.1.0.dev0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==1.4.0->open-r1==0.1.0.dev0) (6.0.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.4.0->open-r1==0.1.0.dev0) (2.6.0+cu124)\n","Collecting hjson (from deepspeed==0.15.4->open-r1==0.1.0.dev0)\n","  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4->open-r1==0.1.0.dev0) (1.1.0)\n","Collecting ninja (from deepspeed==0.15.4->open-r1==0.1.0.dev0)\n","  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4->open-r1==0.1.0.dev0) (9.0.0)\n","Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4->open-r1==0.1.0.dev0) (2.11.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4->open-r1==0.1.0.dev0) (4.67.1)\n","Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.15.4->open-r1==0.1.0.dev0) (12.570.86)\n","Requirement already satisfied: triton>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from liger_kernel==0.5.3->open-r1==0.1.0.dev0) (3.2.0)\n","Collecting latex2sympy2_extended>=1.0.6 (from open-r1==0.1.0.dev0)\n","  Downloading latex2sympy2_extended-1.0.6-py3-none-any.whl.metadata (4.9 kB)\n","Collecting antlr4-python3-runtime==4.13.2 (from latex2sympy2_extended>=1.0.6->open-r1==0.1.0.dev0)\n","  Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl.metadata (304 bytes)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from latex2sympy2_extended>=1.0.6->open-r1==0.1.0.dev0) (1.13.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0->open-r1==0.1.0.dev0) (3.18.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0->open-r1==0.1.0.dev0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0->open-r1==0.1.0.dev0) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0->open-r1==0.1.0.dev0) (0.21.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.2.0->open-r1==0.1.0.dev0) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets>=3.2.0->open-r1==0.1.0.dev0)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.2.0->open-r1==0.1.0.dev0) (2.2.2)\n","Collecting xxhash (from datasets>=3.2.0->open-r1==0.1.0.dev0)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets>=3.2.0->open-r1==0.1.0.dev0)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.2.0->open-r1==0.1.0.dev0)\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=3.2.0->open-r1==0.1.0.dev0) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.2->huggingface-hub[cli]<1.0,>=0.19.2->open-r1==0.1.0.dev0) (4.13.2)\n","Collecting InquirerPy==0.3.4 (from huggingface-hub[cli]<1.0,>=0.19.2->open-r1==0.1.0.dev0)\n","  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n","Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface-hub[cli]<1.0,>=0.19.2->open-r1==0.1.0.dev0)\n","  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n","Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from InquirerPy==0.3.4->huggingface-hub[cli]<1.0,>=0.19.2->open-r1==0.1.0.dev0) (3.0.51)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.1->open-r1==0.1.0.dev0) (8.1.8)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.1->open-r1==0.1.0.dev0) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.1->open-r1==0.1.0.dev0) (3.1.44)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.1->open-r1==0.1.0.dev0) (4.3.7)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.1->open-r1==0.1.0.dev0) (5.29.4)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.1->open-r1==0.1.0.dev0) (2.27.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.1->open-r1==0.1.0.dev0) (1.3.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.1->open-r1==0.1.0.dev0) (75.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect->open-r1==0.1.0.dev0) (1.17.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl@ git+https://github.com/huggingface/trl.git@69ad852e5654a77f1695eb4c608906fe0c7e8624->open-r1==0.1.0.dev0) (13.9.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.2.0->open-r1==0.1.0.dev0) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.2.0->open-r1==0.1.0.dev0) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.2.0->open-r1==0.1.0.dev0) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.2.0->open-r1==0.1.0.dev0) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.2.0->open-r1==0.1.0.dev0) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.2.0->open-r1==0.1.0.dev0) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.2.0->open-r1==0.1.0.dev0) (1.20.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.19.1->open-r1==0.1.0.dev0) (4.0.12)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed==0.15.4->open-r1==0.1.0.dev0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed==0.15.4->open-r1==0.1.0.dev0) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed==0.15.4->open-r1==0.1.0.dev0) (0.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0->open-r1==0.1.0.dev0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0->open-r1==0.1.0.dev0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0->open-r1==0.1.0.dev0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0->open-r1==0.1.0.dev0) (2025.4.26)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->latex2sympy2_extended>=1.0.6->open-r1==0.1.0.dev0) (1.3.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.2.0->open-r1==0.1.0.dev0) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.2.0->open-r1==0.1.0.dev0) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.2.0->open-r1==0.1.0.dev0) (2025.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl@ git+https://github.com/huggingface/trl.git@69ad852e5654a77f1695eb4c608906fe0c7e8624->open-r1==0.1.0.dev0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl@ git+https://github.com/huggingface/trl.git@69ad852e5654a77f1695eb4c608906fe0c7e8624->open-r1==0.1.0.dev0) (2.19.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.19.1->open-r1==0.1.0.dev0) (5.0.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl@ git+https://github.com/huggingface/trl.git@69ad852e5654a77f1695eb4c608906fe0c7e8624->open-r1==0.1.0.dev0) (0.1.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface-hub[cli]<1.0,>=0.19.2->open-r1==0.1.0.dev0) (0.2.13)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.4.0->open-r1==0.1.0.dev0) (3.0.2)\n","Downloading accelerate-1.4.0-py3-none-any.whl (342 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.1/342.1 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading liger_kernel-0.5.3-py3-none-any.whl (113 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading math_verify-0.5.2-py3-none-any.whl (27 kB)\n","Downloading latex2sympy2_extended-1.0.6-py3-none-any.whl (82 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading antlr4_python3_runtime-4.13.2-py3-none-any.whl (144 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.5.1-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n","Building wheels for collected packages: deepspeed, langdetect, trl\n","  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for deepspeed: filename=deepspeed-0.15.4-py3-none-any.whl size=1527833 sha256=cfd66bb89208b1d58e40965b0f1fb7f46c2b37e59e49cccb24b962d30bbf714a\n","  Stored in directory: /root/.cache/pip/wheels/9f/b7/07/035dfeaae31b5766822083a749891e45aab9c72d25a78b7dd0\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=92244ff49cbdb0348d3fa65f8a434f737ffeb771677565bb817cf9a6a700d911\n","  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n","  Building wheel for trl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for trl: filename=trl-0.16.0.dev0-py3-none-any.whl size=323018 sha256=867d417f43993a88278be0b1502cf4090e76c004646e2608e628e2f83d934b33\n","  Stored in directory: /root/.cache/pip/wheels/08/24/1f/6c6247d1a09ee74d1009cb5c5bd1e4be5c9ec09aa9afa6b806\n","Successfully built deepspeed langdetect trl\n","Installing collected packages: hjson, antlr4-python3-runtime, xxhash, pfzy, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, langdetect, hf_transfer, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, latex2sympy2_extended, InquirerPy, nvidia-cusolver-cu12, math-verify, transformers, datasets, liger_kernel, deepspeed, bitsandbytes, accelerate, trl, open-r1\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.51.3\n","    Uninstalling transformers-4.51.3:\n","      Successfully uninstalled transformers-4.51.3\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 1.6.0\n","    Uninstalling accelerate-1.6.0:\n","      Successfully uninstalled accelerate-1.6.0\n","  Running setup.py develop for open-r1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed InquirerPy-0.3.4 accelerate-1.4.0 antlr4-python3-runtime-4.13.2 bitsandbytes-0.45.5 datasets-3.5.1 deepspeed-0.15.4 dill-0.3.8 fsspec-2025.3.0 hf_transfer-0.1.9 hjson-3.1.0 langdetect-1.0.9 latex2sympy2_extended-1.0.6 liger_kernel-0.5.3 math-verify-0.5.2 multiprocess-0.70.16 ninja-1.11.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 open-r1-0.1.0.dev0 pfzy-0.3.4 transformers-4.49.0 trl-0.16.0.dev0 xxhash-3.5.0\n","\u001b[33mWARNING: Package(s) not found: forked_CPPO\u001b[0m\u001b[33m\n","\u001b[0m"]}],"execution_count":2},{"cell_type":"code","source":"import os\nos.chdir('./forked_CPPO')","metadata":{"_uuid":"fe72f3f4-3723-48ec-9cc6-fc79a67f773a","_cell_guid":"b7f206d2-971a-4156-a2da-e13c3ec6a849","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:38:11.320503Z","iopub.execute_input":"2025-04-13T16:38:11.320758Z","iopub.status.idle":"2025-04-13T16:38:11.325518Z","shell.execute_reply.started":"2025-04-13T16:38:11.320725Z","shell.execute_reply":"2025-04-13T16:38:11.324694Z"},"jupyter":{"outputs_hidden":false},"id":"EMq6pbWNKv8T","collapsed":false},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:38:11.326368Z","iopub.execute_input":"2025-04-13T16:38:11.32661Z","iopub.status.idle":"2025-04-13T16:38:11.45375Z","shell.execute_reply.started":"2025-04-13T16:38:11.326589Z","shell.execute_reply":"2025-04-13T16:38:11.452837Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"iY9jAKnwKv8T","outputId":"cf7be905-9f73-4166-f09b-7d36281d49bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["asset\t\t   LICENSE   README0.md  recipes  setup.cfg  src\n","commit_summary.md  Makefile  README.md\t scripts  setup.py\n"]}],"execution_count":4},{"cell_type":"code","source":"#!pip install flash-attn --no-build-isolation\n#!pip install vllm","metadata":{"trusted":true,"id":"a0w2PFoQKv8T"},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from pathlib import Path\n\n\nconfig_content = \"\"\"\ncompute_environment: LOCAL_MACHINE\ndebug: false\n\ndeepspeed_config:\n  gradient_clipping: 1.0\n  zero3_init_flag: true\n  zero_stage: 1\ndistributed_type: no\n\ndowncast_bf16: 'no'\nmachine_rank: 0\nmain_training_function: main\nmixed_precision: bf16\nnum_machines: 1\nnum_processes: 1\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false\n\"\"\"\n\nconfig_path = \"custom_config.yaml\"\nPath(config_path).write_text(config_content)\n\n\n#################################\n\n\nconfig_content2 = \"\"\"\n# Model arguments\nmodel_name_or_path: stpete2/Qwen2.5-0.5B-gsm8k-sft\nmodel_revision: main\ntorch_dtype: bfloat16\nattn_implementation: eager\n\n# Data training arguments\ndataset_name: stpete2/openai-gsm8k-part\nsystem_prompt: |\n  You are a helpful AI Assistant that provides well-reasoned and detailed responses. You first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>\n  ...\n  </think>\n  <answer>\n  ...\n  </answer>\n# GRPO trainer config\nbf16: true\nuse_vllm: false\ndo_eval: false\ngradient_accumulation_steps: 2\ngradient_checkpointing: true\ngradient_checkpointing_kwargs:\n  use_reentrant: false\nhub_model_id: Qwen2.5-0.5B-gsm8k-drgrpocppo\nhub_strategy: every_save\nlearning_rate: 2.0e-06\nlog_completions: true\nlog_level: info\nlogging_first_step: true\nlogging_steps: 1\nlogging_strategy: steps\nlr_scheduler_type: cosine\nmax_prompt_length: 256\nmax_completion_length: 512\nmax_steps: -1\n\nnum_generations: 8\nnum_train_epochs: 1\n\nscale_rewards: false\nmetric: smallest\npruning: 0.75\nallocation: true\n\noutput_dir: data/Qwen2.5-0.5B-gsm8k-drgrpocppo\noverwrite_output_dir: true\nper_device_eval_batch_size: 16\nper_device_train_batch_size: 8\npush_to_hub: false\nreport_to:\n- wandb\nreward_funcs:\n- accuracy\n- format\n- tag_count\nreward_weights:\n- 1.0\n- 1.0\n- 1.0\nsave_strategy: \"epoch\"\nsave_total_limit: 1\nseed: 42\nwarmup_ratio: 0.1\n\"\"\"\n\nconfig_path2 = \"custom_config2.yaml\"\nPath(config_path2).write_text(config_content2)\n\n\n##########################################################\n\n\n!accelerate launch --config_file custom_config.yaml src/open_r1/grpo_gsm.py \\\n--config custom_config2.yaml \\\n--disable_tqdm=False\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:38:11.454847Z","iopub.execute_input":"2025-04-13T16:38:11.455091Z","iopub.status.idle":"2025-04-13T16:38:35.265873Z","shell.execute_reply.started":"2025-04-13T16:38:11.455066Z","shell.execute_reply":"2025-04-13T16:38:35.26512Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"kQLTaNFrKv8U","outputId":"b6002da7-c651-4fbe-e1d3-43fc224cdf80"},"outputs":[{"output_type":"stream","name":"stdout","text":["2025-05-07 13:45:04.940053: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1746625504.959577    3600 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1746625504.965603    3600 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-05-07 13:45:04.985292: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","[2025-05-07 13:45:10,182] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","2025-05-07 13:45:12 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: False\n","2025-05-07 13:45:12 - INFO - __main__ - Model parameters ModelConfig(model_name_or_path='stpete2/Qwen2.5-0.5B-gsm8k-sft', model_revision='main', torch_dtype='bfloat16', trust_remote_code=False, attn_implementation='eager', use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, lora_task_type='CAUSAL_LM', use_rslora=False, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False)\n","2025-05-07 13:45:12 - INFO - __main__ - Script parameters GRPOScriptArguments(dataset_name='stpete2/openai-gsm8k-part', dataset_config=None, dataset_train_split='train', dataset_test_split='test', gradient_checkpointing_use_reentrant=False, ignore_bias_buffers=False, reward_funcs=['accuracy', 'format', 'tag_count'], cosine_min_value_wrong=0.0, cosine_max_value_wrong=-0.5, cosine_min_value_correct=0.5, cosine_max_value_correct=1.0, cosine_max_len=1000, repetition_n_grams=3, repetition_max_penalty=-1.0, code_language='python')\n","2025-05-07 13:45:12 - INFO - __main__ - Training parameters GRPOConfig(\n","_n_gpu=1,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","allocation=True,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","benchmarks=[],\n","beta=0.04,\n","bf16=True,\n","bf16_full_eval=False,\n","callbacks=[],\n","chat_template=None,\n","clip_epsilon=0.2,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=False,\n","do_predict=False,\n","do_train=False,\n","ds3_gather_for_generation=True,\n","epsilon=0.2,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=IntervalStrategy.NO,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","filter_all_correct=True,\n","filter_all_incorrect=True,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=2,\n","gradient_checkpointing=True,\n","gradient_checkpointing_kwargs={'use_reentrant': False},\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=Qwen2.5-0.5B-gsm8k-drgrpocppo,\n","hub_model_revision=main,\n","hub_private_repo=None,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","kl_coef=0.1,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=2e-06,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_completions=True,\n","log_level=info,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=data/Qwen2.5-0.5B-gsm8k-drgrpocppo/runs/May07_13-45-12_33a246c500f9,\n","logging_first_step=True,\n","logging_nan_inf_filter=True,\n","logging_steps=1,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=SchedulerType.COSINE,\n","max_completion_length=512,\n","max_grad_norm=1.0,\n","max_prompt_length=256,\n","max_steps=-1,\n","metric=smallest,\n","metric_for_best_model=None,\n","model_init_kwargs=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","normalize_advantages=True,\n","num_generations=8,\n","num_iterations=1,\n","num_train_epochs=1,\n","optim=OptimizerNames.ADAMW_TORCH,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=data/Qwen2.5-0.5B-gsm8k-drgrpocppo,\n","overwrite_hub_revision=False,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=16,\n","per_device_train_batch_size=8,\n","policy_loss=none,\n","prediction_loss_only=False,\n","pruning=0.75,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_revision=False,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","ref_model_mixup_alpha=0.6,\n","ref_model_sync_steps=512,\n","reinforce_pp_beta=0.1,\n","reinforce_variant=none,\n","remove_unused_columns=False,\n","report_to=['wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","reward_scaling_factor=1.0,\n","reward_weights=[1.0, 1.0, 1.0],\n","run_name=data/Qwen2.5-0.5B-gsm8k-drgrpocppo,\n","sample_num=0,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=SaveStrategy.EPOCH,\n","save_total_limit=1,\n","scale_rewards=False,\n","seed=42,\n","skip_memory_metrics=True,\n","split_batches=None,\n","sync_ref_model=False,\n","system_prompt=You are a helpful AI Assistant that provides well-reasoned and detailed responses. You first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>\n","...\n","</think>\n","<answer>\n","...\n","</answer>\n",",\n","temperature=0.9,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","use_reward_scaling=True,\n","use_vllm=False,\n","vllm_device=auto,\n","vllm_dtype=auto,\n","vllm_enable_prefix_caching=True,\n","vllm_gpu_memory_utilization=0.9,\n","vllm_guided_decoding_regex=None,\n","vllm_max_model_len=None,\n","wandb_entity=None,\n","wandb_name=None,\n","wandb_project=None,\n","warmup_ratio=0.1,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","README.md: 100% 55.0/55.0 [00:00<00:00, 383kB/s]\n","Generating dataset openai-gsm8k-part (/root/.cache/huggingface/datasets/stpete2___openai-gsm8k-part/default/0.0.0/a196359a8dfc66a7c2bb6d3433bb8e1e3d9dbbc0)\n","2025-05-07 13:45:16 - INFO - datasets.builder - Generating dataset openai-gsm8k-part (/root/.cache/huggingface/datasets/stpete2___openai-gsm8k-part/default/0.0.0/a196359a8dfc66a7c2bb6d3433bb8e1e3d9dbbc0)\n","Downloading and preparing dataset openai-gsm8k-part/default to /root/.cache/huggingface/datasets/stpete2___openai-gsm8k-part/default/0.0.0/a196359a8dfc66a7c2bb6d3433bb8e1e3d9dbbc0...\n","2025-05-07 13:45:16 - INFO - datasets.builder - Downloading and preparing dataset openai-gsm8k-part/default to /root/.cache/huggingface/datasets/stpete2___openai-gsm8k-part/default/0.0.0/a196359a8dfc66a7c2bb6d3433bb8e1e3d9dbbc0...\n","gsm8k_split_0.parquet: 100% 130k/130k [00:00<00:00, 17.0MB/s]\n","Downloading took 0.0 min\n","2025-05-07 13:45:17 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","2025-05-07 13:45:17 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n","Generating train split\n","2025-05-07 13:45:17 - INFO - datasets.builder - Generating train split\n","Generating train split: 100% 400/400 [00:00<00:00, 9585.28 examples/s]\n","All the splits matched successfully.\n","2025-05-07 13:45:17 - INFO - datasets.utils.info_utils - All the splits matched successfully.\n","Dataset openai-gsm8k-part downloaded and prepared to /root/.cache/huggingface/datasets/stpete2___openai-gsm8k-part/default/0.0.0/a196359a8dfc66a7c2bb6d3433bb8e1e3d9dbbc0. Subsequent calls will reuse this data.\n","2025-05-07 13:45:17 - INFO - datasets.builder - Dataset openai-gsm8k-part downloaded and prepared to /root/.cache/huggingface/datasets/stpete2___openai-gsm8k-part/default/0.0.0/a196359a8dfc66a7c2bb6d3433bb8e1e3d9dbbc0. Subsequent calls will reuse this data.\n","tokenizer_config.json: 100% 4.69k/4.69k [00:00<00:00, 18.7MB/s]\n","vocab.json: 100% 2.78M/2.78M [00:00<00:00, 11.4MB/s]\n","merges.txt: 100% 1.67M/1.67M [00:00<00:00, 6.85MB/s]\n","tokenizer.json: 100% 11.4M/11.4M [00:00<00:00, 129MB/s]\n","added_tokens.json: 100% 605/605 [00:00<00:00, 5.79MB/s]\n","special_tokens_map.json: 100% 616/616 [00:00<00:00, 5.78MB/s]\n","chat_template.jinja: 100% 2.43k/2.43k [00:00<00:00, 22.8MB/s]\n","[INFO|tokenization_utils_base.py:2050] 2025-05-07 13:45:21,015 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--stpete2--Qwen2.5-0.5B-gsm8k-sft/snapshots/700386ce2a6581dce388b449f47a6dc8b2acfc17/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-05-07 13:45:21,015 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--stpete2--Qwen2.5-0.5B-gsm8k-sft/snapshots/700386ce2a6581dce388b449f47a6dc8b2acfc17/merges.txt\n","[INFO|tokenization_utils_base.py:2050] 2025-05-07 13:45:21,015 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--stpete2--Qwen2.5-0.5B-gsm8k-sft/snapshots/700386ce2a6581dce388b449f47a6dc8b2acfc17/tokenizer.json\n","[INFO|tokenization_utils_base.py:2050] 2025-05-07 13:45:21,015 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--stpete2--Qwen2.5-0.5B-gsm8k-sft/snapshots/700386ce2a6581dce388b449f47a6dc8b2acfc17/added_tokens.json\n","[INFO|tokenization_utils_base.py:2050] 2025-05-07 13:45:21,015 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--stpete2--Qwen2.5-0.5B-gsm8k-sft/snapshots/700386ce2a6581dce388b449f47a6dc8b2acfc17/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-05-07 13:45:21,015 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--stpete2--Qwen2.5-0.5B-gsm8k-sft/snapshots/700386ce2a6581dce388b449f47a6dc8b2acfc17/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-05-07 13:45:21,015 >> loading file chat_template.jinja from cache at /root/.cache/huggingface/hub/models--stpete2--Qwen2.5-0.5B-gsm8k-sft/snapshots/700386ce2a6581dce388b449f47a6dc8b2acfc17/chat_template.jinja\n","[INFO|tokenization_utils_base.py:2313] 2025-05-07 13:45:21,504 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Map:   0% 0/400 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/stpete2___openai-gsm8k-part/default/0.0.0/a196359a8dfc66a7c2bb6d3433bb8e1e3d9dbbc0/cache-5c478f9c7f87cc0f.arrow\n","2025-05-07 13:45:21 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/stpete2___openai-gsm8k-part/default/0.0.0/a196359a8dfc66a7c2bb6d3433bb8e1e3d9dbbc0/cache-5c478f9c7f87cc0f.arrow\n","Map: 100% 400/400 [00:00<00:00, 16923.95 examples/s]\n","2025-05-07 13:45:21 - INFO - __main__ - *** Initializing model kwargs ***\n","config.json: 100% 750/750 [00:00<00:00, 7.37MB/s]\n","adapter_config.json: 100% 712/712 [00:00<00:00, 5.14MB/s]\n","config.json: 100% 681/681 [00:00<00:00, 5.08MB/s]\n","[INFO|configuration_utils.py:699] 2025-05-07 13:45:23,058 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987/config.json\n","[INFO|configuration_utils.py:771] 2025-05-07 13:45:23,060 >> Model config Qwen2Config {\n","  \"_name_or_path\": \"Qwen/Qwen2.5-0.5B\",\n","  \"architectures\": [\n","    \"Qwen2ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 151643,\n","  \"eos_token_id\": 151643,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 896,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4864,\n","  \"max_position_embeddings\": 32768,\n","  \"max_window_layers\": 24,\n","  \"model_type\": \"qwen2\",\n","  \"num_attention_heads\": 14,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 2,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 1000000.0,\n","  \"sliding_window\": 32768,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.49.0\",\n","  \"use_cache\": false,\n","  \"use_mrope\": false,\n","  \"use_sliding_window\": false,\n","  \"vocab_size\": 151936\n","}\n","\n","model.safetensors: 100% 988M/988M [00:03<00:00, 323MB/s]\n","[INFO|modeling_utils.py:3982] 2025-05-07 13:45:26,393 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987/model.safetensors\n","[INFO|modeling_utils.py:1633] 2025-05-07 13:45:26,403 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.\n","[INFO|configuration_utils.py:1140] 2025-05-07 13:45:26,405 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 151643,\n","  \"eos_token_id\": 151643,\n","  \"use_cache\": false\n","}\n","\n","[WARNING|logging.py:329] 2025-05-07 13:45:26,409 >> Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.\n","[INFO|modeling_utils.py:4970] 2025-05-07 13:45:26,465 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n","\n","[INFO|modeling_utils.py:4978] 2025-05-07 13:45:26,465 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-0.5B.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\n","generation_config.json: 100% 138/138 [00:00<00:00, 1.17MB/s]\n","[INFO|configuration_utils.py:1095] 2025-05-07 13:45:26,943 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-05-07 13:45:26,943 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 151643,\n","  \"eos_token_id\": 151643,\n","  \"max_new_tokens\": 2048\n","}\n","\n","adapter_model.safetensors: 100% 1.09M/1.09M [00:00<00:00, 196MB/s]\n","[INFO|trainer.py:746] 2025-05-07 13:45:28,897 >> Using auto half precision backend\n","2025-05-07 13:45:29 - INFO - __main__ - *** Train ***\n","[INFO|trainer.py:2405] 2025-05-07 13:45:29,546 >> ***** Running training *****\n","[INFO|trainer.py:2406] 2025-05-07 13:45:29,546 >>   Num examples = 400\n","[INFO|trainer.py:2407] 2025-05-07 13:45:29,546 >>   Num Epochs = 1\n","[INFO|trainer.py:2408] 2025-05-07 13:45:29,546 >>   Instantaneous batch size per device = 8\n","[INFO|trainer.py:2411] 2025-05-07 13:45:29,546 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n","[INFO|trainer.py:2412] 2025-05-07 13:45:29,546 >>   Gradient Accumulation steps = 2\n","[INFO|trainer.py:2413] 2025-05-07 13:45:29,546 >>   Total optimization steps = 50\n","[INFO|trainer.py:2414] 2025-05-07 13:45:29,547 >>   Number of trainable parameters = 0\n","[INFO|integration_utils.py:817] 2025-05-07 13:45:29,549 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path ./wandb/wandb/ wasn't writable, using system temp directory\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstpeteishii\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.10\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/wandb/run-20250507_134529-oo0tr5oz\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdata/Qwen2.5-0.5B-gsm8k-drgrpocppo\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/stpeteishii/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/stpeteishii/huggingface/runs/oo0tr5oz\u001b[0m\n","  0% 0/50 [00:00<?, ?it/s]Begin Training\n","[WARNING|logging.py:329] 2025-05-07 13:45:31,228 >> `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n","Begin Training\n","{'loss': 0.0001, 'grad_norm': 0.0, 'learning_rate': 4e-07, 'pruning_rate': 0.75, 'completion_length': 335.625, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.125, 'reward': 0.125, 'reward_std': 0.1767766922712326, 'second_item': 3.788259709835984e-05, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 3.7883000914007425e-05, 'kl': 0.0014625644544139504, 'clip_ratio': 0.0, 'epoch': 0.02}\n","{'loss': -0.2438, 'grad_norm': 0.0, 'learning_rate': 8e-07, 'pruning_rate': 0.75, 'completion_length': 256.0, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.125, 'reward': 0.125, 'reward_std': 0.1767766922712326, 'second_item': 0.0001267267216462642, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.0001267260522581637, 'kl': 0.000767018151236698, 'clip_ratio': 0.0, 'epoch': 0.04}\n","{'loss': -0.037, 'grad_norm': 0.0, 'learning_rate': 1.2e-06, 'pruning_rate': 0.75, 'completion_length': 351.1875, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': 0.0001899509097711416, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00018995074970007408, 'kl': 0.0006426879845093936, 'clip_ratio': 0.0, 'epoch': 0.06}\n","{'loss': -0.0732, 'grad_norm': 0.0, 'learning_rate': 1.6e-06, 'pruning_rate': 0.75, 'completion_length': 347.625, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.15625, 'reward': 0.15625, 'reward_std': 0.22097086906433105, 'second_item': 0.00015454506501555443, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00015454439562745392, 'kl': 0.0005805437540402636, 'clip_ratio': 0.0, 'epoch': 0.08}\n","{'loss': -0.1338, 'grad_norm': 0.0, 'learning_rate': 2e-06, 'pruning_rate': 0.75, 'completion_length': 285.8125, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.125, 'reward': 0.125, 'reward_std': 0.1767766922712326, 'second_item': 0.00044338175212033093, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00044338160660117865, 'kl': 0.0007186965813161805, 'clip_ratio': 0.0, 'epoch': 0.1}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.997564050259824e-06, 'pruning_rate': 0.75, 'completion_length': 317.25, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'second_item': -0.0005675263564626221, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -0.0005675263564626221, 'kl': 0.0008526703750248998, 'clip_ratio': 0.0, 'epoch': 0.12}\n","{'loss': -0.0833, 'grad_norm': 0.0, 'learning_rate': 1.99026806874157e-06, 'pruning_rate': 0.75, 'completion_length': 272.0625, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.125, 'reward': 0.125, 'reward_std': 0.1767766922712326, 'second_item': 0.0005226421963016037, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.0005226424291322473, 'kl': 0.0015573681448586285, 'clip_ratio': 0.0, 'epoch': 0.14}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9781476007338054e-06, 'pruning_rate': 0.75, 'completion_length': 407.5, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'second_item': -0.0005146608418726828, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -0.0005146608418726828, 'kl': 0.0008203252218663692, 'clip_ratio': 0.0, 'epoch': 0.16}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9612616959383188e-06, 'pruning_rate': 0.75, 'completion_length': 326.25, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'second_item': -0.0001917168847285211, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -0.0001917168847285211, 'kl': 0.0012104810448363423, 'clip_ratio': 0.0, 'epoch': 0.18}\n","{'loss': -0.0935, 'grad_norm': 0.0, 'learning_rate': 1.9396926207859082e-06, 'pruning_rate': 0.75, 'completion_length': 341.875, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.1875, 'reward': 0.1875, 'reward_std': 0.2651650384068489, 'second_item': 0.000833094643894583, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.0008330941782332957, 'kl': 0.0013655608636327088, 'clip_ratio': 0.0, 'epoch': 0.2}\n","{'loss': -0.1975, 'grad_norm': 0.0, 'learning_rate': 1.9135454576426007e-06, 'pruning_rate': 0.75, 'completion_length': 325.4375, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': -0.00031297843088395894, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -0.00031297875102609396, 'kl': 0.0007677648682147264, 'clip_ratio': 0.0, 'epoch': 0.22}\n","{'loss': -0.1243, 'grad_norm': 0.0, 'learning_rate': 1.8829475928589268e-06, 'pruning_rate': 0.75, 'completion_length': 265.8125, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.140625, 'reward': 0.140625, 'reward_std': 0.19887378066778183, 'second_item': 0.0017569258925504982, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.0017569269402883947, 'kl': 0.0012501131277531385, 'clip_ratio': 0.0, 'epoch': 0.24}\n","{'loss': -0.0562, 'grad_norm': 0.0, 'learning_rate': 1.8480480961564257e-06, 'pruning_rate': 0.75, 'completion_length': 292.0, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': 0.0003901770542142913, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00039017770905047655, 'kl': 0.0005952689098194242, 'clip_ratio': 0.0, 'epoch': 0.26}\n","{'loss': 0.0082, 'grad_norm': 0.0, 'learning_rate': 1.8090169943749474e-06, 'pruning_rate': 0.75, 'completion_length': 357.75, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.1875, 'reward': 0.1875, 'reward_std': 0.2651650384068489, 'second_item': 0.00013348487846087664, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00013348477659747005, 'kl': 0.001074018538929522, 'clip_ratio': 0.0, 'epoch': 0.28}\n","{'loss': -0.0319, 'grad_norm': 0.0, 'learning_rate': 1.766044443118978e-06, 'pruning_rate': 0.75, 'completion_length': 305.25, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.078125, 'reward': 0.078125, 'reward_std': 0.11048543453216553, 'second_item': -0.0003685635747388005, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -0.00036856261431239545, 'kl': 0.0008956753299571574, 'clip_ratio': 0.0, 'epoch': 0.3}\n","{'loss': 0.0001, 'grad_norm': 0.0, 'learning_rate': 1.719339800338651e-06, 'pruning_rate': 0.75, 'completion_length': 308.625, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': 0.00010739232993728365, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00010739333811216056, 'kl': 0.0020478484802879393, 'clip_ratio': 0.0, 'epoch': 0.32}\n","{'loss': -0.0817, 'grad_norm': 0.0, 'learning_rate': 1.669130606358858e-06, 'pruning_rate': 0.75, 'completion_length': 246.1875, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': 0.0008749698899919167, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.0008749694243306294, 'kl': 0.0008518582326360047, 'clip_ratio': 0.0, 'epoch': 0.34}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.615661475325658e-06, 'pruning_rate': 0.75, 'completion_length': 363.75, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.125, 'reward': 0.125, 'reward_std': 0.0, 'second_item': 8.157368574757129e-05, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 8.157368574757129e-05, 'kl': 0.0009214875753968954, 'clip_ratio': 0.0, 'epoch': 0.36}\n","{'loss': -0.1531, 'grad_norm': 0.0, 'learning_rate': 1.5591929034707466e-06, 'pruning_rate': 0.75, 'completion_length': 322.25, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': 0.0005126409523654729, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.0005126411851961166, 'kl': 0.0008065011643338948, 'clip_ratio': 0.0, 'epoch': 0.38}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5e-06, 'pruning_rate': 0.75, 'completion_length': 376.6875, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.125, 'reward': 0.125, 'reward_std': 0.0, 'second_item': -6.954399941605516e-05, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -6.954399941605516e-05, 'kl': 0.0012683314271271229, 'clip_ratio': 0.0, 'epoch': 0.4}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4383711467890773e-06, 'pruning_rate': 0.75, 'completion_length': 282.8125, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': 0.00019312805306981318, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00019312641234137118, 'kl': 0.0008687884837854654, 'clip_ratio': 0.0, 'epoch': 0.42}\n","{'loss': -0.0355, 'grad_norm': 0.0, 'learning_rate': 1.374606593415912e-06, 'pruning_rate': 0.75, 'completion_length': 296.5, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.03125, 'reward': 0.03125, 'reward_std': 0.04419417306780815, 'second_item': 0.00030612653063144535, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.0003061267052544281, 'kl': 0.0010956129408441484, 'clip_ratio': 0.0, 'epoch': 0.44}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3090169943749473e-06, 'pruning_rate': 0.75, 'completion_length': 385.625, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'second_item': 0.0006240872608032078, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.0006240872608032078, 'kl': 0.0005969911580905318, 'clip_ratio': 0.0, 'epoch': 0.46}\n","{'loss': 0.0333, 'grad_norm': 0.0, 'learning_rate': 1.2419218955996676e-06, 'pruning_rate': 0.75, 'completion_length': 312.0625, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': 0.0003457881393842399, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.0003457873244769871, 'kl': 0.0020527952001430094, 'clip_ratio': 0.0, 'epoch': 0.48}\n","{'loss': 0.077, 'grad_norm': 0.0, 'learning_rate': 1.1736481776669305e-06, 'pruning_rate': 0.75, 'completion_length': 309.75, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': -8.947772130341036e-05, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -8.947745936893625e-05, 'kl': 0.0007304514583665878, 'clip_ratio': 0.0, 'epoch': 0.5}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1045284632676535e-06, 'pruning_rate': 0.75, 'completion_length': 350.1875, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': -0.00017759310139808804, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -0.00017759355250746012, 'kl': 0.000842755296616815, 'clip_ratio': 0.0, 'epoch': 0.52}\n","{'loss': 0.0001, 'grad_norm': 0.0, 'learning_rate': 1.034899496702501e-06, 'pruning_rate': 0.75, 'completion_length': 365.75, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'second_item': -5.066371522843838e-05, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -5.066371522843838e-05, 'kl': 0.0012786199804395437, 'clip_ratio': 0.0, 'epoch': 0.54}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.651005032974993e-07, 'pruning_rate': 0.75, 'completion_length': 362.75, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': -0.0003086606120632496, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -0.00030866084853187203, 'kl': 0.000980935845291242, 'clip_ratio': 0.0, 'epoch': 0.56}\n","{'loss': 0.1116, 'grad_norm': 0.0, 'learning_rate': 8.954715367323466e-07, 'pruning_rate': 0.75, 'completion_length': 321.375, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': -0.00028166627816972323, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -0.00028166598713141866, 'kl': 0.0006182427314342931, 'clip_ratio': 0.0, 'epoch': 0.58}\n","{'loss': -0.0971, 'grad_norm': 0.0, 'learning_rate': 8.263518223330696e-07, 'pruning_rate': 0.75, 'completion_length': 341.25, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.21875, 'reward': 0.21875, 'reward_std': 0.30935920402407646, 'second_item': 0.001019090039335424, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.0010190907632932067, 'kl': 0.0016458053141832352, 'clip_ratio': 0.0, 'epoch': 0.6}\n","{'loss': 0.0001, 'grad_norm': 0.0, 'learning_rate': 7.580781044003324e-07, 'pruning_rate': 0.75, 'completion_length': 271.1875, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'second_item': -0.00045259639227879234, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -0.00045259639227879234, 'kl': 0.0034095767769031227, 'clip_ratio': 0.0, 'epoch': 0.62}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.909830056250526e-07, 'pruning_rate': 0.75, 'completion_length': 344.8125, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'second_item': -0.00023356566089205444, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -0.00023356566089205444, 'kl': 0.00046312855556607246, 'clip_ratio': 0.0, 'epoch': 0.64}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.253934065840879e-07, 'pruning_rate': 0.75, 'completion_length': 396.5, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'second_item': 0.00033825525679276325, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00033825525679276325, 'kl': 0.0011909917811863124, 'clip_ratio': 0.0, 'epoch': 0.66}\n","{'loss': 0.1397, 'grad_norm': 0.0, 'learning_rate': 5.616288532109224e-07, 'pruning_rate': 0.75, 'completion_length': 362.625, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': 0.000208478988497518, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00020847856649197638, 'kl': 0.0010870571131817997, 'clip_ratio': 0.0, 'epoch': 0.68}\n","{'loss': -0.155, 'grad_norm': 0.0, 'learning_rate': 5.000000000000002e-07, 'pruning_rate': 0.75, 'completion_length': 333.0625, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.125, 'reward': 0.125, 'reward_std': 0.1767766922712326, 'second_item': 0.0007843872881494462, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.0007843878993298858, 'kl': 0.0008768850238993764, 'clip_ratio': 0.0, 'epoch': 0.7}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.408070965292533e-07, 'pruning_rate': 0.75, 'completion_length': 274.3125, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'second_item': 0.0008392851450480521, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.0008392851450480521, 'kl': 0.0007856414304114878, 'clip_ratio': 0.0, 'epoch': 0.72}\n","{'loss': 0.0829, 'grad_norm': 0.0, 'learning_rate': 3.843385246743417e-07, 'pruning_rate': 0.75, 'completion_length': 319.0, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': -0.00047466118121519685, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -0.0004746616177726537, 'kl': 0.0008660705934744328, 'clip_ratio': 0.0, 'epoch': 0.74}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.308693936411421e-07, 'pruning_rate': 0.75, 'completion_length': 389.0625, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'second_item': 0.00011450641613919288, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00011450641613919288, 'kl': 0.0008799242787063122, 'clip_ratio': 0.0, 'epoch': 0.76}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.8066019966134904e-07, 'pruning_rate': 0.75, 'completion_length': 361.125, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'second_item': 0.00030105860787443817, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00030105860787443817, 'kl': 0.0014313304563984275, 'clip_ratio': 0.0, 'epoch': 0.78}\n","{'loss': 0.0286, 'grad_norm': 0.0, 'learning_rate': 2.339555568810221e-07, 'pruning_rate': 0.75, 'completion_length': 298.25, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.125, 'reward': 0.125, 'reward_std': 0.1767766922712326, 'second_item': -0.0004977790540579008, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -0.000497777306009084, 'kl': 0.0008888333977665752, 'clip_ratio': 0.0, 'epoch': 0.8}\n","{'loss': -0.1055, 'grad_norm': 0.0, 'learning_rate': 1.9098300562505264e-07, 'pruning_rate': 0.75, 'completion_length': 373.75, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.25, 'reward': 0.25, 'reward_std': 0.3535533845424652, 'second_item': 0.00019584796245908365, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00019584555411711335, 'kl': 0.000869126757606864, 'clip_ratio': 0.0, 'epoch': 0.82}\n","{'loss': 0.0001, 'grad_norm': 0.0, 'learning_rate': 1.5195190384357404e-07, 'pruning_rate': 0.75, 'completion_length': 309.75, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'second_item': 0.00023543230054201558, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00023543230054201558, 'kl': 0.0022011884720996022, 'clip_ratio': 0.0, 'epoch': 0.84}\n","{'loss': 0.04, 'grad_norm': 0.0, 'learning_rate': 1.1705240714107301e-07, 'pruning_rate': 0.75, 'completion_length': 307.5625, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.109375, 'reward': 0.109375, 'reward_std': 0.15467959642410278, 'second_item': 0.00023786035308148712, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00023786010569892824, 'kl': 0.0009856732795014977, 'clip_ratio': 0.0, 'epoch': 0.86}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.645454235739902e-08, 'pruning_rate': 0.75, 'completion_length': 420.8125, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.078125, 'reward': 0.078125, 'reward_std': 0.11048543080687523, 'second_item': 2.3651884475839324e-05, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 2.3651693481951952e-05, 'kl': 0.0006111289258114994, 'clip_ratio': 0.0, 'epoch': 0.88}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.030737921409168e-08, 'pruning_rate': 0.75, 'completion_length': 301.125, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.078125, 'reward': 0.078125, 'reward_std': 0.11048543453216553, 'second_item': -8.796964630164439e-05, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -8.796983456704766e-05, 'kl': 0.00043308804742991924, 'clip_ratio': 0.0, 'epoch': 0.9}\n","{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.87383040616811e-08, 'pruning_rate': 0.75, 'completion_length': 265.8125, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'second_item': -0.00037091436388436705, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -0.00037091436388436705, 'kl': 0.0007155819184845313, 'clip_ratio': 0.0, 'epoch': 0.92}\n","{'loss': -0.0417, 'grad_norm': 0.0, 'learning_rate': 2.185239926619431e-08, 'pruning_rate': 0.75, 'completion_length': 346.4375, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.25, 'reward': 0.25, 'reward_std': 0.3535533770918846, 'second_item': 4.457777686184272e-05, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 4.4577871449291706e-05, 'kl': 0.0009256982884835452, 'clip_ratio': 0.0, 'epoch': 0.94}\n","{'loss': -0.0625, 'grad_norm': 0.0, 'learning_rate': 9.731931258429638e-09, 'pruning_rate': 0.75, 'completion_length': 315.25, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0625, 'reward': 0.0625, 'reward_std': 0.0883883461356163, 'second_item': 0.000513090559252305, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.000513091898028506, 'kl': 0.0009763895068317652, 'clip_ratio': 0.0, 'epoch': 0.96}\n","{'loss': -0.048, 'grad_norm': 0.0, 'learning_rate': 2.435949740175802e-09, 'pruning_rate': 0.75, 'completion_length': 268.0625, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.109375, 'reward': 0.109375, 'reward_std': 0.11048543453216553, 'second_item': 0.00037517972668865696, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': 0.00037518018507398665, 'kl': 0.0012659071071539074, 'clip_ratio': 0.0, 'epoch': 0.98}\n","{'loss': 0.0001, 'grad_norm': 0.0, 'learning_rate': 0.0, 'pruning_rate': 0.75, 'completion_length': 307.9375, 'rewards/accuracy_reward': 0.0, 'rewards/format_reward': 0.0, 'rewards/tag_count_reward': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'second_item': -0.0003180983621859923, 'first_item': 0.0, 'first_item_div_second_item': 0.0, 'total_sum': -0.0003180983621859923, 'kl': 0.0021767158759757876, 'clip_ratio': 0.0, 'epoch': 1.0}\n","100% 50/50 [50:22<00:00, 59.13s/it][INFO|trainer.py:3942] 2025-05-07 14:35:53,519 >> Saving model checkpoint to data/Qwen2.5-0.5B-gsm8k-drgrpocppo/checkpoint-50\n","[INFO|configuration_utils.py:909] 2025-05-07 14:35:53,521 >> Configuration saved in data/Qwen2.5-0.5B-gsm8k-drgrpocppo/checkpoint-50/generation_config.json\n","[INFO|modeling_utils.py:2825] 2025-05-07 14:35:53,521 >> Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n","[INFO|configuration_utils.py:699] 2025-05-07 14:35:54,004 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987/config.json\n","[INFO|configuration_utils.py:771] 2025-05-07 14:35:54,005 >> Model config Qwen2Config {\n","  \"architectures\": [\n","    \"Qwen2ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 151643,\n","  \"eos_token_id\": 151643,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 896,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4864,\n","  \"max_position_embeddings\": 32768,\n","  \"max_window_layers\": 24,\n","  \"model_type\": \"qwen2\",\n","  \"num_attention_heads\": 14,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 2,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 1000000.0,\n","  \"sliding_window\": 32768,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.49.0\",\n","  \"use_cache\": true,\n","  \"use_mrope\": false,\n","  \"use_sliding_window\": false,\n","  \"vocab_size\": 151936\n","}\n","\n","[INFO|modeling_utils.py:2831] 2025-05-07 14:35:54,006 >> To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n","[INFO|modeling_utils.py:3040] 2025-05-07 14:35:54,025 >> Model weights saved in data/Qwen2.5-0.5B-gsm8k-drgrpocppo/checkpoint-50/adapter_model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-05-07 14:35:54,027 >> tokenizer config file saved in data/Qwen2.5-0.5B-gsm8k-drgrpocppo/checkpoint-50/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-05-07 14:35:54,027 >> Special tokens file saved in data/Qwen2.5-0.5B-gsm8k-drgrpocppo/checkpoint-50/special_tokens_map.json\n","[INFO|trainer.py:3942] 2025-05-07 14:35:54,236 >> Saving model checkpoint to data/Qwen2.5-0.5B-gsm8k-drgrpocppo/checkpoint-50\n","[INFO|configuration_utils.py:909] 2025-05-07 14:35:54,238 >> Configuration saved in data/Qwen2.5-0.5B-gsm8k-drgrpocppo/checkpoint-50/generation_config.json\n","[INFO|modeling_utils.py:2825] 2025-05-07 14:35:54,239 >> Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n","[INFO|configuration_utils.py:699] 2025-05-07 14:35:54,721 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987/config.json\n","[INFO|configuration_utils.py:771] 2025-05-07 14:35:54,722 >> Model config Qwen2Config {\n","  \"architectures\": [\n","    \"Qwen2ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 151643,\n","  \"eos_token_id\": 151643,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 896,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4864,\n","  \"max_position_embeddings\": 32768,\n","  \"max_window_layers\": 24,\n","  \"model_type\": \"qwen2\",\n","  \"num_attention_heads\": 14,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 2,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 1000000.0,\n","  \"sliding_window\": 32768,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.49.0\",\n","  \"use_cache\": true,\n","  \"use_mrope\": false,\n","  \"use_sliding_window\": false,\n","  \"vocab_size\": 151936\n","}\n","\n","[INFO|modeling_utils.py:2831] 2025-05-07 14:35:54,723 >> To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n","[INFO|modeling_utils.py:3040] 2025-05-07 14:35:54,736 >> Model weights saved in data/Qwen2.5-0.5B-gsm8k-drgrpocppo/checkpoint-50/adapter_model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-05-07 14:35:54,737 >> tokenizer config file saved in data/Qwen2.5-0.5B-gsm8k-drgrpocppo/checkpoint-50/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-05-07 14:35:54,738 >> Special tokens file saved in data/Qwen2.5-0.5B-gsm8k-drgrpocppo/checkpoint-50/special_tokens_map.json\n","[INFO|trainer.py:2657] 2025-05-07 14:35:54,936 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 3025.3886, 'train_samples_per_second': 0.132, 'train_steps_per_second': 0.017, 'train_loss': -0.02664570699522301, 'epoch': 1.0}\n","100% 50/50 [50:24<00:00, 60.48s/it]\n","\n","Training + Eval time: 2992.767297254\n","\n","Eval time: 1.4857539109981417\n","\n","Training time: 2991.281543343002\n","***** train metrics *****\n","  total_flos               =        0GF\n","  train_loss               =    -0.0266\n","  train_runtime            = 0:50:25.38\n","  train_samples            =        400\n","  train_samples_per_second =      0.132\n","  train_steps_per_second   =      0.017\n","2025-05-07 14:35:54 - INFO - __main__ - *** Save model ***\n","[INFO|trainer.py:3942] 2025-05-07 14:35:54,944 >> Saving model checkpoint to data/Qwen2.5-0.5B-gsm8k-drgrpocppo\n","[INFO|configuration_utils.py:909] 2025-05-07 14:35:54,946 >> Configuration saved in data/Qwen2.5-0.5B-gsm8k-drgrpocppo/generation_config.json\n","[INFO|modeling_utils.py:2825] 2025-05-07 14:35:54,946 >> Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n","[INFO|configuration_utils.py:699] 2025-05-07 14:35:55,424 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987/config.json\n","[INFO|configuration_utils.py:771] 2025-05-07 14:35:55,425 >> Model config Qwen2Config {\n","  \"architectures\": [\n","    \"Qwen2ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 151643,\n","  \"eos_token_id\": 151643,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 896,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4864,\n","  \"max_position_embeddings\": 32768,\n","  \"max_window_layers\": 24,\n","  \"model_type\": \"qwen2\",\n","  \"num_attention_heads\": 14,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 2,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 1000000.0,\n","  \"sliding_window\": 32768,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.49.0\",\n","  \"use_cache\": true,\n","  \"use_mrope\": false,\n","  \"use_sliding_window\": false,\n","  \"vocab_size\": 151936\n","}\n","\n","[INFO|modeling_utils.py:2831] 2025-05-07 14:35:55,425 >> To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n","[INFO|modeling_utils.py:3040] 2025-05-07 14:35:55,438 >> Model weights saved in data/Qwen2.5-0.5B-gsm8k-drgrpocppo/adapter_model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-05-07 14:35:55,439 >> tokenizer config file saved in data/Qwen2.5-0.5B-gsm8k-drgrpocppo/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-05-07 14:35:55,440 >> Special tokens file saved in data/Qwen2.5-0.5B-gsm8k-drgrpocppo/special_tokens_map.json\n","2025-05-07 14:35:55 - INFO - __main__ - Model saved to data/Qwen2.5-0.5B-gsm8k-drgrpocppo\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n","[INFO|configuration_utils.py:423] 2025-05-07 14:35:55,632 >> Configuration saved in data/Qwen2.5-0.5B-gsm8k-drgrpocppo/config.json\n"]}],"execution_count":6},{"cell_type":"code","source":"import shutil\nfrom google.colab import files\nfolder_path = \"data\"\nzip_filename = \"data.zip\"\nshutil.make_archive(folder_path, 'zip', folder_path)\nfiles.download(zip_filename)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"z4gkHnHLbsC5","outputId":"0ed73f76-1879-461b-850f-d2ea21f543ec"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_75e2bbf8-7f9d-4c50-928f-518822aee03a\", \"data.zip\", 9534850)"]},"metadata":{}}],"execution_count":7}]}