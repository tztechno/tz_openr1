{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# OpenR1 Qwen2-0.5B-math-sft","metadata":{}},{"cell_type":"markdown","source":"- gpu: T4*2\n- model: Qwen/Qwen2-0.5B\n- data: stpete2/openr1-math-part\n- method: sft\n- output: Qwen2-0.5B-math-sft","metadata":{}},{"cell_type":"markdown","source":"## Open-R1 \nis an open initiative to replicate and extend the techniques behind DeepSeek-R1, a state-of-the-art reasoning model, in a fully transparent and collaborative way: \n\nhttps://github.com/huggingface/open-r1\n\n","metadata":{}},{"cell_type":"markdown","source":"By selecting the model, dataset, and method, and running the training command from the command line, we were able to successfully perform training using the OpenR1 environment.\n\nCconsidering the limitations of the notebook environment, I limited the model and data to a minimum. And the following techniques are used. \n\n* 1. Using LoRA (Low-Rank Adaptation)\n* 2. Gradient checkpointing\n* 3. Batching optimizations\n* 4. BF16 mixed precision\n* 5. Sequence length limit\n* 6. Data packing\n\nThis setting is far from sufficient for effective training, but on the other hand, it allows us to check the operation of the method in a short time.\n\nThis minimal configuration allows for rapid validation of the training pipeline even with limited resources, and is a useful starting point before scaling up to larger experiments.","metadata":{}},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport wandb\nuser_secrets = UserSecretsClient()\nsecret_value = user_secrets.get_secret(\"wandb_api_key\")\nwandb.login(key=secret_value)\n\n# save metrics into wandb folder\nimport os\nos.environ[\"WANDB_DIR\"] = \"./wandb\"\nwandb.init(project=\"250413or\", mode=\"online\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T23:49:56.653136Z","iopub.execute_input":"2025-04-10T23:49:56.653374Z","iopub.status.idle":"2025-04-10T23:49:56.783407Z","shell.execute_reply.started":"2025-04-10T23:49:56.65335Z","shell.execute_reply":"2025-04-10T23:49:56.782197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/huggingface/open-r1.git\n!pip install -e ./open-r1\n!pip show open-r1","metadata":{"_uuid":"56441817-9a26-48a8-9e2a-20d0519b1368","_cell_guid":"c938dd8b-8728-417e-b2b8-e5ea9a6531cb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-10T23:49:56.784571Z","iopub.execute_input":"2025-04-10T23:49:56.784983Z","iopub.status.idle":"2025-04-10T23:51:01.063258Z","shell.execute_reply.started":"2025-04-10T23:49:56.784941Z","shell.execute_reply":"2025-04-10T23:51:01.061877Z"},"_kg_hide-output":true,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.chdir('./open-r1')","metadata":{"_uuid":"fe72f3f4-3723-48ec-9cc6-fc79a67f773a","_cell_guid":"b7f206d2-971a-4156-a2da-e13c3ec6a849","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-10T23:51:01.064866Z","iopub.execute_input":"2025-04-10T23:51:01.065246Z","iopub.status.idle":"2025-04-10T23:51:01.07132Z","shell.execute_reply.started":"2025-04-10T23:51:01.065212Z","shell.execute_reply":"2025-04-10T23:51:01.069877Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T23:51:01.07377Z","iopub.execute_input":"2025-04-10T23:51:01.074164Z","iopub.status.idle":"2025-04-10T23:51:01.213961Z","shell.execute_reply.started":"2025-04-10T23:51:01.074131Z","shell.execute_reply":"2025-04-10T23:51:01.212679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\n\nconfig_content = \"\"\"\ncompute_environment: LOCAL_MACHINE\ndebug: false\ndeepspeed_config:\n  gradient_clipping: 1.0\n  zero3_init_flag: true\n  zero_stage: 3\ndistributed_type: DEEPSPEED\ndowncast_bf16: 'no'\nmachine_rank: 0\nmain_training_function: main\nmixed_precision: bf16\nnum_machines: 1\nnum_processes: 2\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false\n\"\"\"\n\nconfig_path = \"custom_config.yaml\"\nPath(config_path).write_text(config_content)\n\n!accelerate launch --config_file custom_config.yaml src/open_r1/sft.py \\\n    --model_name_or_path Qwen/Qwen2-0.5B \\\n    --dataset_name stpete2/openr1-math-part \\\n    --learning_rate 1.0e-5 \\\n    --num_train_epochs 1 \\\n    --packing \\\n    --max_seq_length 1024 \\\n    --per_device_train_batch_size 2 \\\n    --gradient_accumulation_steps 8 \\\n    --gradient_checkpointing \\\n    --bf16 \\\n    --use_peft \\\n    --lora_alpha 16 \\\n    --lora_dropout 0.1 \\\n    --lora_r 8 \\\n    --output_dir data/Qwen2-0.5B-math-sft","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}